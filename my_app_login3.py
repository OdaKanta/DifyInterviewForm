import streamlit as st
import requests
import os
import datetime
import pandas as pd
from streamlit_gsheets import GSheetsConnection
import json
import base64
import io

# --- è¿½åŠ ãƒ©ã‚¤ãƒ–ãƒ©ãƒª ---
from streamlit_mic_recorder import mic_recorder
from openai import OpenAI
import gspread

# --- ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆæ¥ç¶š ---
conn = st.connection("gsheets", type=GSheetsConnection)

# --- è¨­å®š ---
DIFY_API_KEY = st.secrets["DIFY_API_KEY"]
openai_client = OpenAI(api_key=st.secrets["OPENAI_API_KEY"])

BASE_URL = "https://api.dify.ai/v1"
FILE_VARIABLE_KEY = "material"
MATERIALS = {
    "åœ°å­¦åŸºç¤ã€€ç¬¬1è¬›": {"pdf": "geology01.pdf", "keywords": "keywords01.txt"},
    "åœ°å­¦åŸºç¤ã€€ç¬¬3è¬›": {"pdf": "geology03.pdf", "keywords": "keywords03.txt"}
}

headers = {
    "Authorization": f"Bearer {DIFY_API_KEY}"
}

# --- ãƒ­ã‚°ã‚¤ãƒ³æ©Ÿèƒ½ï¼ˆãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰èªè¨¼ç‰ˆï¼‰ ---
def login():
    """IDã¨ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã«ã‚ˆã‚‹èªè¨¼æ©Ÿèƒ½"""
    if "username" not in st.session_state:
        st.session_state.username = None

    if not st.session_state.username:
        with st.form("login_form"):
            st.write("å­¦ç¿’ã‚’é–‹å§‹ã™ã‚‹ã«ã¯ãƒ­ã‚°ã‚¤ãƒ³ã—ã¦ãã ã•ã„")
            
            # ãƒ¦ãƒ¼ã‚¶ãƒ¼IDå…¥åŠ›
            username_input = st.text_input("ãƒ¦ãƒ¼ã‚¶ãƒ¼ID", key="login_user_id")
            # ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰å…¥åŠ›ï¼ˆtype="password"ã§æ–‡å­—ã‚’éš ã™ï¼‰
            password_input = st.text_input("ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰", type="password", key="login_password")
            
            submitted = st.form_submit_button("ãƒ­ã‚°ã‚¤ãƒ³")
            
            if submitted:
                # 1. IDãŒ secrets ã«å­˜åœ¨ã™ã‚‹ã‹ï¼Ÿ
                if username_input in st.secrets["passwords"]:
                    # 2. ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ãŒä¸€è‡´ã™ã‚‹ã‹ï¼Ÿ
                    correct_password = st.secrets["passwords"][username_input]
                    if password_input == correct_password:
                        st.session_state.username = username_input
                        st.success("ãƒ­ã‚°ã‚¤ãƒ³æˆåŠŸï¼")
                        st.rerun()
                    else:
                        st.error("ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ãŒé–“é•ã£ã¦ã„ã¾ã™ã€‚")
                else:
                    st.error("ãƒ¦ãƒ¼ã‚¶ãƒ¼IDãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
        st.stop()

# --- Difyé€£æºé–¢æ•°ç¾¤ ---
def upload_local_file_to_dify(file_path, user_id):
    if not os.path.exists(file_path):
        st.error(f"ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {file_path}")
        return None
    url = f"{BASE_URL}/files/upload"
    with open(file_path, "rb") as f:
        files = {'file': (os.path.basename(file_path), f, 'application/pdf')}
        data = {'user': user_id}
        try:
            response = requests.post(url, headers=headers, files=files, data=data)
            response.raise_for_status()
            return response.json().get('id')
        except Exception as e:
            st.error(f"å†…éƒ¨ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {e}")
            return None

def send_chat_message(query, conversation_id, file_id_to_send, user_id, material_name):
    url = f"{BASE_URL}/chat-messages"
    inputs = {"material_name": material_name}
    if file_id_to_send:
        inputs[FILE_VARIABLE_KEY] = {
            "type": "document", 
            "transfer_method": "local_file",
            "upload_file_id": file_id_to_send
        }
    payload = {
        "inputs": inputs,
        "query": query,
        "response_mode": "blocking",
        "conversation_id": conversation_id,
        "user": user_id,
    }
    try:
        response = requests.post(url, headers=headers, json=payload)
        if response.status_code == 400:
            # 400ã‚¨ãƒ©ãƒ¼ã®æ™‚ã¯Difyã‹ã‚‰ã®è©³ç´°ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¡¨ç¤º
            st.error(f"Difyã‚¨ãƒ©ãƒ¼è©³ç´°: {response.text}") 
        response.raise_for_status()
        return response.json()
    except Exception as e:
        st.error(f"é€šä¿¡ã‚¨ãƒ©ãƒ¼: {e}")
        return None

# --- ãƒ­ã‚°ä¿å­˜æ©Ÿèƒ½ ---
def save_log_to_sheet(session, user, material, system_question, user_answer):
    try:
        created_date = datetime.datetime.now(datetime.timezone(datetime.timedelta(hours=9))).strftime('%Y-%m-%d %H:%M:%S')
        new_row = [session, user, material, system_question, user_answer, created_date]
        
        # Secretsã‹ã‚‰ã‚µãƒ¼ãƒ“ã‚¹ã‚¢ã‚«ã‚¦ãƒ³ãƒˆæƒ…å ±ã‚’å–å¾—ã—ã¦ç›´æ¥èªè¨¼
        # st.secrets["connections"]["gsheets"] ã®æ§‹é€ ã«åˆã‚ã›ã¦æŒ‡å®šã—ã¦ãã ã•ã„
        creds_dict = st.secrets["connections"]["gsheets"]
        gc = gspread.service_account_from_dict(creds_dict)
        
        # ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã‚’é–‹ã„ã¦1è¡Œè¿½è¨˜
        sh = gc.open_by_url(st.secrets["spreadsheet_url"])
        ws = sh.get_worksheet(0)
        ws.append_row(new_row)
        
    except Exception as e:
        st.error(f"ãƒ­ã‚°ä¿å­˜ã‚¨ãƒ©ãƒ¼ (è¿½è¨˜å¤±æ•—): {e}")

def transcribe_audio(audio_bytes, keyword_file):
    try:
        # 1. ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã¨æ•´å½¢
        vocab_prompt = ""
        if os.path.exists(keyword_file):
            with open(keyword_file, "r", encoding="utf-8") as f:
                content = f.read()
                
            all_keywords = []
            # è¡Œã”ã¨ã«åˆ†å‰²ï¼ˆæ”¹è¡ŒåŒºåˆ‡ã‚Šå¯¾å¿œï¼‰
            for line in content.splitlines():
                # å„è¡Œã‚’ã•ã‚‰ã«ã‚«ãƒ³ãƒã§åˆ†å‰²ï¼ˆã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šå¯¾å¿œï¼‰
                parts = line.split(',')
                for p in parts:
                    clean_word = p.strip()
                    if clean_word:
                        all_keywords.append(clean_word)
            
            # é‡è¤‡ã‚’é™¤å»ã—ã¦ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šã®æ–‡å­—åˆ—ã«ã™ã‚‹
            unique_keywords = list(dict.fromkeys(all_keywords))
            vocab_prompt = ",".join(unique_keywords)
        
        # 2. éŸ³å£°èªè­˜ã®å®Ÿè¡Œ
        audio_file = io.BytesIO(audio_bytes)
        audio_file.name = "input.wav"
        
        transcript = openai_client.audio.transcriptions.create(
            model="whisper-1", 
            file=audio_file, 
            language="ja",
            prompt=vocab_prompt, # æŒ‡ç¤ºæ–‡ãªã—ã€‚å˜èªã®ç¾…åˆ—ã‚’ç›´æ¥æ¸¡ã™ã®ãŒæ­£è§£ã€‚
            temperature=0.0
        )
        return transcript.text
    except Exception as e:
        st.error(f"éŸ³å£°èªè­˜ã‚¨ãƒ©ãƒ¼: {e}")
        return ""

def correct_transcript(text, keyword_file):
    """Whisperã®èª¤èªè­˜ã‚’LLMã§ç›´ã™é–¢æ•°"""
    try:
        # 1. ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã¨æ•´å½¢
        keywords_str = ""
        if os.path.exists(keyword_file):
            with open(keyword_file, "r", encoding="utf-8") as f:
                content = f.read()
                
            all_keywords = []
            # è¡Œã”ã¨ã«åˆ†å‰²ï¼ˆæ”¹è¡ŒåŒºåˆ‡ã‚Šå¯¾å¿œï¼‰
            for line in content.splitlines():
                # å„è¡Œã‚’ã•ã‚‰ã«ã‚«ãƒ³ãƒã§åˆ†å‰²ï¼ˆã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šå¯¾å¿œï¼‰
                parts = line.split(',')
                for p in parts:
                    clean_word = p.strip()
                    if clean_word:
                        all_keywords.append(clean_word)
            
            # é‡è¤‡ã‚’é™¤å»ã—ã¦ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šã®æ–‡å­—åˆ—ã«ã™ã‚‹
            unique_keywords = list(dict.fromkeys(all_keywords))
            keywords_str = ",".join(unique_keywords)

        prompt = f"""
        ç”Ÿå¾’ãŒä¸­å­¦ç†ç§‘ã®æˆæ¥­ã«ã¤ã„ã¦æŒ¯ã‚Šè¿”ã£ãŸéš›ã®éŒ²éŸ³ã‚’æ–‡å­—èµ·ã“ã—ã—ã¾ã—ãŸãŒã€èªè­˜ç²¾åº¦ã®é™ç•Œã«ã‚ˆã‚Šèª¤å­—è„±å­—ãŒã‚ã‚‹ã‹ã‚‚ã—ã‚Œãªã„ã®ã§ã€ä¿®æ­£ã—ã¦ãã ã•ã„ã€‚

        â–  ä¿®æ­£ã®æŒ‡ç¤º
        - å…ƒã®æ–‡ç« ã®æ„å›³ã¯ä¿æŒã™ã‚‹ï¼ˆå­¦ç¿’è€…ã«ã‚ˆã‚‹é–“é•ã£ãŸèª¬æ˜ã¯ã‚ãˆã¦ä¿®æ­£ã›ãšãã®ã¾ã¾ï¼‰ã€‚
        - èª¤å­—è„±å­—ã‚„åŒéŸ³ç•°ç¾©èªã®å¤‰æ›ãƒŸã‚¹ã‚’ä¿®æ­£ã—ã€ä¸è¦ãªãƒ•ã‚£ãƒ©ãƒ¼ï¼ˆãˆãƒ¼ã€ã‚ã®ãƒ¼ç­‰ï¼‰ã‚„ç„¡æ„å‘³ãªæ–‡ç« ã‚’å‰Šé™¤ã™ã‚‹ã€‚
        - å‡ºåŠ›ã¯ä¿®æ­£å¾Œã®æ–‡ç« ã®ã¿å‡ºåŠ›ã—ã€ä½™è¨ˆãªæ–‡ç« ã‚’å‹æ‰‹ã«ä»˜ã‘åŠ ãˆã¦ã¯ãªã‚‰ãªã„ã€‚
        - ä¿®æ­£ç®‡æ‰€ãŒè¦‹ã¤ã‹ã‚‰ãªã„ã»ã©çŸ­ã„å…¥åŠ›ã®å ´åˆã§ã‚‚ã€æ–‡å¥ã‚’è¨€ã‚ãšã«ãã®ã¾ã¾å‡ºåŠ›ã›ã‚ˆã€‚
        
        â–  åŸæ–‡ï¼ˆã„ã‹ã«çŸ­ãã¦ã‚‚ã€ã©ã†ã¿ã¦ã‚‚ã¾ã¨ã‚‚ãªèª¬æ˜ã§ãªãã¦ã‚‚ã€æ–‡å¥ã‚’è¨€ã£ã¦ã¯ãªã‚‰ãªã„ï¼‰
        {text}

        {f"â–  æˆæ¥­å†…å®¹ã«å«ã¾ã‚Œã‚‹é‡è¦èªå¥ï¼ˆã“ã®å˜èªã¸ã®èª¤å¤‰æ›ãŒç–‘ã‚ã‚Œã‚‹å ´åˆã«å‚è€ƒã«ã›ã‚ˆï¼‰: {keywords_str}" if keywords_str else ""}
        """
        response = openai_client.chat.completions.create(
            model="gpt-4o-mini", # é«˜é€Ÿãƒ»å®‰ä¾¡ãªãƒ¢ãƒ‡ãƒ«
            messages=[
                {"role": "system", "content": "ã‚ãªãŸã¯å„ªç§€ãªæ ¡æ­£è€…ã§ã™ã€‚éŸ³å£°æ›¸ãèµ·ã“ã—ã«ã¿ã‚‰ã‚Œã‚‹èª¤å­—è„±å­—ãªã©ã‚’ä¿®æ­£ã—ã¦ãã ã•ã„ã€‚"},
                {"role": "user", "content": prompt}
            ],
            temperature=0.0
        )
        return response.choices[0].message.content.strip()
    except:
        return text

def text_to_speech_autoplay(text):
    try:
        response = openai_client.audio.speech.create(
            model="tts-1-hd", voice="nova", input=text
        )
        audio_bytes = response.content
        audio_base64 = base64.b64encode(audio_bytes).decode('utf-8')
        audio_tag = f'<audio autoplay="true" style="display:none"><source src="data:audio/mp3;base64,{audio_base64}" type="audio/mp3"></audio>'
        return audio_tag
    except Exception as e:
        st.error(f"éŸ³å£°åˆæˆã‚¨ãƒ©ãƒ¼: {e}")
        return None

# ==========================================
# ãƒ¡ã‚¤ãƒ³å‡¦ç†
# ==========================================
st.set_page_config(page_title="è¬›ç¾©å¾©ç¿’æ”¯æ´ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆ", page_icon="ğŸ¤–")
st.title("è¬›ç¾©å¾©ç¿’æ”¯æ´ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆ")

login()
current_user = st.session_state.username
st.sidebar.write(f"ãƒ­ã‚°ã‚¤ãƒ³ä¸­: {current_user}")

# ã‚»ãƒƒã‚·ãƒ§ãƒ³å¤‰æ•°
if "messages" not in st.session_state:
    st.session_state.messages = []
if "conversation_id" not in st.session_state:
    st.session_state.conversation_id = ""
if "current_file_id" not in st.session_state:
    st.session_state.current_file_id = None
if "selected_material" not in st.session_state:
    st.session_state.selected_material = None
if "last_bot_message" not in st.session_state:
    st.session_state.last_bot_message = ""
if "audio_html" not in st.session_state:
    st.session_state.audio_html = None
if "prev_audio_bytes" not in st.session_state:
    st.session_state.prev_audio_bytes = None
if "temp_user_input" not in st.session_state:
    st.session_state.temp_user_input = ""
if "input_to_process" not in st.session_state:
    st.session_state.input_to_process = None
if "is_completed" not in st.session_state:
    st.session_state.is_completed = False

# 1. è¬›ç¾©è³‡æ–™ã®é¸æŠã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹
if not st.session_state.selected_material:
    st.subheader("ğŸ“š å­¦ç¿’ã™ã‚‹è¬›ç¾©è³‡æ–™ã‚’é¸æŠã—ã¦ãã ã•ã„")
    selected = st.radio(
        "è¬›ç¾©ãƒªã‚¹ãƒˆ",
        options=list(MATERIALS.keys()),
        index=None
    )
    
    if st.button("å­¦ç¿’ã‚’é–‹å§‹ã™ã‚‹"):
        if selected:
            st.session_state.selected_material = selected
            st.rerun()
        else:
            st.warning("è¬›ç¾©è³‡æ–™ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚")
    st.stop() # é¸æŠã•ã‚Œã‚‹ã¾ã§ä¸‹ã®å‡¦ç†ï¼ˆãƒãƒ£ãƒƒãƒˆï¼‰ã«é€²ã¾ãªã„

material_info = MATERIALS[st.session_state.selected_material]
target_material_path = material_info["pdf"]
target_keyword_path = material_info["keywords"]

# --- ç·Šæ€¥ãƒªã‚»ãƒƒãƒˆ ---
if st.sidebar.button("âš ï¸ ä¼šè©±ã‚’ãƒªã‚»ãƒƒãƒˆ"):
    for key in list(st.session_state.keys()):
        if key not in ["username"]: # ãƒ­ã‚°ã‚¤ãƒ³æƒ…å ±ã¯æ®‹ã™
            del st.session_state[key]
    st.rerun()

# 3. è‡ªå‹•åˆæœŸåŒ–ï¼ˆä¿®æ­£ç‰ˆï¼šAPIã‚’å©ã‹ãšã€é™çš„ã«é–‹å§‹ã™ã‚‹ï¼‰
if not st.session_state.conversation_id:
    # ã¾ã ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å±¥æ­´ãŒãªã„å ´åˆã®ã¿å®Ÿè¡Œ
    if not st.session_state.messages:
        with st.spinner("ã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ã‚¢ãƒ¼ã‚’æº–å‚™ä¸­..."):
            
            # 1. ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã ã‘ã¯æ¸ˆã¾ã›ã¦ãŠãï¼ˆIDç¢ºä¿ï¼‰
            if not st.session_state.current_file_id:
                file_id = upload_local_file_to_dify(target_material_path, current_user)
                if file_id:
                    st.session_state.current_file_id = file_id
                else:
                    st.error("ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
                    st.stop()
            
            # 2. Difyã«ã¯ä½•ã‚‚é€ã‚‰ãšã€ã“ã“ã§å‹æ‰‹ã«ç¬¬ä¸€å£°ã‚’è¡¨ç¤ºã™ã‚‹
            static_first_msg = "æˆæ¥­å†…å®¹ã«ã¤ã„ã¦å­¦ã‚“ã ã“ã¨ã‚’æ•™ãˆã¦ãã ã•ã„ã€‚"
            
            # ç”»é¢è¡¨ç¤ºç”¨ãƒªã‚¹ãƒˆã«è¿½åŠ 
            st.session_state.messages.append({"role": "assistant", "content": static_first_msg})
            
            # ãƒ­ã‚°ä¿å­˜ç”¨ï¼ˆæ¬¡ã®ã‚¿ãƒ¼ãƒ³ã®ãŸã‚ï¼‰
            st.session_state.last_bot_message = static_first_msg
            
            # éŸ³å£°ç”Ÿæˆï¼ˆã“ã“ã ã‘ã¯OpenAI APIã‚’å©ãã¾ã™ãŒã€Difyã¯å©ãã¾ã›ã‚“ï¼‰
            st.session_state.audio_html = text_to_speech_autoplay(static_first_msg)
            
            # ç”»é¢æ›´æ–°ã—ã¦è¡¨ç¤º
            st.rerun()

# 4. ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®è¡¨ç¤º
chat_container = st.container(height=400)

with chat_container:
    for msg in st.session_state.messages:
        with st.chat_message(msg["role"]):
            st.write(msg["content"])
    if st.session_state.audio_html:
        st.markdown(st.session_state.audio_html, unsafe_allow_html=True)

if st.session_state.is_completed:
    st.success("ğŸ‰ å…¨ã¦ã®å­¦ç¿’é …ç›®ã‚’ç¢ºèªã—ã¾ã—ãŸã€‚ãŠç–²ã‚Œæ§˜ã§ã—ãŸï¼")
    st.balloons() # ãŠç¥ã„ã®æ¼”å‡º

# 5. å…¥åŠ›ã‚¨ãƒªã‚¢ & 6. å…¥åŠ›å‡¦ç†ãƒ­ã‚¸ãƒƒã‚¯ï¼ˆçµ±åˆãƒ»é †åºä¿®æ­£ç‰ˆï¼‰
def submit_text():
    if st.session_state[input_key]:
        st.session_state.input_to_process = st.session_state[input_key] 

# ã‚»ãƒƒã‚·ãƒ§ãƒ³å¤‰æ•°åˆæœŸåŒ–ï¼ˆæ—¢å­˜ã®å ´æ‰€ã«è¿½åŠ ï¼‰
if "input_method" not in st.session_state:
    st.session_state.input_method = "text"

# --- 5. å…¥åŠ›ã‚¨ãƒªã‚¢ ---
col_input, col_send, col_mic = st.columns([5, 1, 1])
input_key = f"chat_input_text_{current_user}"
display_value = st.session_state.temp_user_input

# if st.session_state.temp_user_input:
#     st.session_state[input_key] = st.session_state.temp_user_input
#     st.session_state.input_method = "voice"
#     st.session_state.temp_user_input = ""

if display_value:
    st.session_state.input_method = "voice"

with col_input:
    st.text_input(
        label="ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å…¥åŠ›",
        value=display_value,
        key=input_key,
        placeholder="ãƒ†ã‚­ã‚¹ãƒˆã‚’å…¥åŠ›ã—ã¦Enter...",
        label_visibility="collapsed",
        on_change=submit_text
    )
if display_value:
    st.session_state.temp_user_input = ""

with col_send:
    # ä¿®æ­£ï¼štemp_user_input ã§ã¯ãªã input_key (ç¾åœ¨ã®å…¥åŠ›å†…å®¹) ã‚’å‚ç…§
    if st.button("é€ä¿¡", use_container_width=True):
        st.session_state.input_to_process = st.session_state[input_key]
        # rerunã™ã‚‹ã¨ç¾åœ¨ã®å…¥åŠ›æ–¹æ³•(text or voice)ã‚’ç¶­æŒã—ãŸã¾ã¾é€ä¿¡å‡¦ç†ã¸é€²ã‚€
        st.rerun()

# --- A. ãƒã‚¤ã‚¯å…¥åŠ›ã¨éŸ³å£°å‡¦ç†ï¼ˆå…ˆå‡ºã—ï¼‰ ---
with col_mic:
    audio = mic_recorder(
        start_prompt="ğŸ¤", 
        stop_prompt="ğŸŸ¥", 
        key='recorder', 
        format="wav"
    )

# éŸ³å£°ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹å ´åˆã€ã™ãã«å‡¦ç†ã—ã¦ session_state ã‚’æ›´æ–°ã™ã‚‹
if audio:
    if audio['bytes'] != st.session_state.prev_audio_bytes:
        st.session_state.prev_audio_bytes = audio['bytes']
        with st.spinner("éŸ³å£°å‡¦ç†ä¸­..."): # æ–‡è¨€ã‚’çŸ­ã
            transcribed_text = transcribe_audio(audio['bytes'], target_keyword_path)
            if transcribed_text:
                # miniãƒ¢ãƒ‡ãƒ«ã§é«˜é€Ÿæ ¡æ­£
                st.session_state.temp_user_input = correct_transcript(transcribed_text, target_keyword_path)
                st.session_state.input_method = "voice"
                st.rerun() # æ–‡å­—ãŒå…¥ã£ãŸçŠ¶æ…‹ã§å³åº§ã«å†æç”»

# --- C. é€ä¿¡å‡¦ç†ï¼ˆEnterãŒæŠ¼ã•ã‚ŒãŸå¾Œã®å‡¦ç†ï¼‰ ---
# ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯(submit_text)ã«ã‚ˆã£ã¦ input_to_process ã«å€¤ãŒå…¥ã£ã¦ã„ãŸã‚‰å®Ÿè¡Œ
final_prompt = None

if st.session_state.input_to_process:
    final_prompt = st.session_state.input_to_process
    st.session_state.input_to_process = None
    st.session_state.audio_html = None

# é€ä¿¡å®Ÿè¡Œ
if final_prompt:
    st.session_state.messages.append({"role": "user", "content": final_prompt})
    
    with chat_container:
        with st.chat_message("user"):
            st.write(final_prompt)

    with st.spinner("æ€è€ƒä¸­..."):
        response = send_chat_message(
            query=final_prompt,
            conversation_id=st.session_state.conversation_id,
            file_id_to_send=st.session_state.current_file_id,
            user_id=current_user,
            material_name=st.session_state.selected_material
        )
        
        if response:
            st.session_state.conversation_id = response.get('conversation_id')
            answer_text = response.get('answer', '')
            is_finished = response.get('metadata', {}).get('workflow_outputs', {}).get('is_finished', False)
            if is_finished:
                st.session_state.is_completed = True
            st.session_state.messages.append({"role": "assistant", "content": answer_text})
            
            save_log_to_sheet(
                session=st.session_state.conversation_id,
                user=current_user,
                material=st.session_state.selected_material,
                system_question=st.session_state.last_bot_message,
                user_answer=final_prompt
            )
            
            st.session_state.last_bot_message = answer_text
            st.session_state.audio_html = text_to_speech_autoplay(answer_text)
            st.session_state.temp_user_input = ""

            st.rerun()
