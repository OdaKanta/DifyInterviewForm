import streamlit as st
import requests
import os
import datetime
import pandas as pd
from streamlit_gsheets import GSheetsConnection
import json
import base64
import io

# --- è¿½åŠ ãƒ©ã‚¤ãƒ–ãƒ©ãƒª ---
from streamlit_mic_recorder import mic_recorder
from openai import OpenAI
import gspread

# --- ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆæ¥ç¶š ---
conn = st.connection("gsheets", type=GSheetsConnection)

# --- è¨­å®š ---
DIFY_API_KEY = st.secrets["DIFY_API_KEY"]
openai_client = OpenAI(api_key=st.secrets["OPENAI_API_KEY"])

BASE_URL = "https://api.dify.ai/v1"
FILE_VARIABLE_KEY = "material"
MATERIALS = {
    "åœ°å­¦åŸºç¤ã€€ç¬¬1è¬›": {"pdf": "geology01.pdf", "keywords": "keywords01.txt"},
    "åœ°å­¦åŸºç¤ã€€ç¬¬3è¬›": {"pdf": "geology03.pdf", "keywords": "keywords03.txt"}
}

headers = {
    "Authorization": f"Bearer {DIFY_API_KEY}"
}

# --- ãƒ­ã‚°ã‚¤ãƒ³æ©Ÿèƒ½ï¼ˆãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰èªè¨¼ç‰ˆï¼‰ ---
def login():
    """IDã¨ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã«ã‚ˆã‚‹èªè¨¼æ©Ÿèƒ½"""
    if "username" not in st.session_state:
        st.session_state.username = None

    if not st.session_state.username:
        with st.form("login_form"):
            st.write("å­¦ç¿’ã‚’é–‹å§‹ã™ã‚‹ã«ã¯ãƒ­ã‚°ã‚¤ãƒ³ã—ã¦ãã ã•ã„")
            
            # ãƒ¦ãƒ¼ã‚¶ãƒ¼IDå…¥åŠ›
            username_input = st.text_input("ãƒ¦ãƒ¼ã‚¶ãƒ¼ID")
            # ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰å…¥åŠ›ï¼ˆtype="password"ã§æ–‡å­—ã‚’éš ã™ï¼‰
            password_input = st.text_input("ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰", type="password")
            
            submitted = st.form_submit_button("ãƒ­ã‚°ã‚¤ãƒ³")
            
            if submitted:
                # 1. IDãŒ secrets ã«å­˜åœ¨ã™ã‚‹ã‹ï¼Ÿ
                if username_input in st.secrets["passwords"]:
                    # 2. ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ãŒä¸€è‡´ã™ã‚‹ã‹ï¼Ÿ
                    correct_password = st.secrets["passwords"][username_input]
                    if password_input == correct_password:
                        st.session_state.username = username_input
                        st.success("ãƒ­ã‚°ã‚¤ãƒ³æˆåŠŸï¼")
                        st.rerun()
                    else:
                        st.error("ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ãŒé–“é•ã£ã¦ã„ã¾ã™ã€‚")
                else:
                    st.error("ãƒ¦ãƒ¼ã‚¶ãƒ¼IDãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
        st.stop()

# --- Difyé€£æºé–¢æ•°ç¾¤ ---
def upload_local_file_to_dify(file_path, user_id):
    if not os.path.exists(file_path):
        st.error(f"ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {file_path}")
        return None
    url = f"{BASE_URL}/files/upload"
    with open(file_path, "rb") as f:
        files = {'file': (os.path.basename(file_path), f, 'application/pdf')}
        data = {'user': user_id}
        try:
            response = requests.post(url, headers=headers, files=files, data=data)
            response.raise_for_status()
            return response.json().get('id')
        except Exception as e:
            st.error(f"å†…éƒ¨ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {e}")
            return None

def send_chat_message(query, conversation_id, file_id_to_send, user_id):
    url = f"{BASE_URL}/chat-messages"
    inputs = {}
    if file_id_to_send:
        inputs[FILE_VARIABLE_KEY] = {
            "type": "document", 
            "transfer_method": "local_file",
            "upload_file_id": file_id_to_send
        }
    payload = {
        "inputs": inputs,
        "query": query,
        "response_mode": "blocking",
        "conversation_id": conversation_id,
        "user": user_id,
    }
    try:
        response = requests.post(url, headers=headers, json=payload)
        response.raise_for_status()
        return response.json()
    except Exception as e:
        st.error(f"é€šä¿¡ã‚¨ãƒ©ãƒ¼: {e}")
        return None

# --- ãƒ­ã‚°ä¿å­˜æ©Ÿèƒ½ ---
def save_log_to_sheet(session, user, material, system_question, user_answer):
    try:
        created_date = datetime.datetime.now(datetime.timezone(datetime.timedelta(hours=9))).strftime('%Y-%m-%d %H:%M:%S')
        new_row = [session, user, material, system_question, user_answer, created_date]
        
        # Secretsã‹ã‚‰ã‚µãƒ¼ãƒ“ã‚¹ã‚¢ã‚«ã‚¦ãƒ³ãƒˆæƒ…å ±ã‚’å–å¾—ã—ã¦ç›´æ¥èªè¨¼
        # st.secrets["connections"]["gsheets"] ã®æ§‹é€ ã«åˆã‚ã›ã¦æŒ‡å®šã—ã¦ãã ã•ã„
        creds_dict = st.secrets["connections"]["gsheets"]
        gc = gspread.service_account_from_dict(creds_dict)
        
        # ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã‚’é–‹ã„ã¦1è¡Œè¿½è¨˜
        sh = gc.open_by_url(st.secrets["spreadsheet_url"])
        ws = sh.get_worksheet(0)
        ws.append_row(new_row)
        
    except Exception as e:
        st.error(f"ãƒ­ã‚°ä¿å­˜ã‚¨ãƒ©ãƒ¼ (è¿½è¨˜å¤±æ•—): {e}")

def transcribe_audio(audio_bytes, keyword_file):
    try:
        # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿
        vocab_prompt = ""
        if os.path.exists(keyword_file):
            with open(keyword_file, "r", encoding="utf-8") as f:
                # ä¸€è¡Œä¸€èªã‚’ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šã®æ–‡å­—åˆ—ã«å¤‰æ›
                lines = [line.strip() for line in f if line.strip()]
                vocab_prompt = ",".join(lines)
        
        audio_file = io.BytesIO(audio_bytes)
        audio_file.name = "input.wav"
        
        transcript = openai_client.audio.transcriptions.create(
            model="whisper-1", 
            file=audio_file, 
            language="ja",
            prompt=vocab_prompt, # èª­ã¿è¾¼ã‚“ã ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’ã‚»ãƒƒãƒˆ
            temperature=0.0
        )
        return transcript.text
    except Exception as e:
        st.error(f"éŸ³å£°èªè­˜ã‚¨ãƒ©ãƒ¼: {e}")
        return ""

def correct_transcript(text):
    """Whisperã®èª¤èªè­˜ã‚’LLMã§ç›´ã™é–¢æ•°"""
    try:
        completion = openai_client.chat.completions.create(
            model="gpt-4o-mini", # é«˜é€Ÿãƒ»å®‰ä¾¡ãªãƒ¢ãƒ‡ãƒ«
            messages=[
                {"role": "system", "content": "ã‚ãªãŸã¯å„ªç§€ãªæ ¡æ­£è€…ã§ã™ã€‚ä»¥ä¸‹ã®æ–‡ç« ã¯ã‚ã‚‹ãƒ†ã‚­ã‚¹ãƒˆã®éŸ³å£°èªè­˜çµæœã§ã‚ã‚Šã€æ—¥æœ¬èªã¨ã—ã¦ä¸è‡ªç„¶ãªæ–‡å­—ã‚„è¨€è‘‰ã€è¡¨ç¾ã§ã‚ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚æ–‡è„ˆã‚’è€ƒæ…®ã—ã¦ã€æ˜ã‚‰ã‹ãªèª¤ã‚Šï¼ˆåŒéŸ³ç•°ç¾©èªãªã©ï¼‰ã‚’ä¿®æ­£ã—ã¦ãã ã•ã„ã€‚å…ƒã®æ„å‘³ã¯å¤§ããå¤‰ãˆã¦ã¯ã„ã‘ã¾ã›ã‚“ã€ä½™è¨ˆãªè¿”äº‹ã‚’ã›ãšã€ä¿®æ­£å¾Œã®ãƒ†ã‚­ã‚¹ãƒˆã®ã¿ã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚"},
                {"role": "user", "content": text}
            ],
            temperature=0
        )
        return completion.choices[0].message.content
    except:
        return text

def text_to_speech_autoplay(text):
    try:
        response = openai_client.audio.speech.create(
            model="tts-1-hd", voice="nova", input=text
        )
        audio_bytes = response.content
        audio_base64 = base64.b64encode(audio_bytes).decode('utf-8')
        audio_tag = f'<audio autoplay="true" style="display:none"><source src="data:audio/mp3;base64,{audio_base64}" type="audio/mp3"></audio>'
        return audio_tag
    except Exception as e:
        st.error(f"éŸ³å£°åˆæˆã‚¨ãƒ©ãƒ¼: {e}")
        return None

# ==========================================
# ãƒ¡ã‚¤ãƒ³å‡¦ç†
# ==========================================
st.set_page_config(page_title="è¬›ç¾©ã®å¾©ç¿’", page_icon="ğŸ¤–")
st.title("ğŸ¤– è¬›ç¾©æŒ¯ã‚Šè¿”ã‚Šã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ã‚¢ãƒ¼")

login()
current_user = st.session_state.username
st.sidebar.write(f"ãƒ­ã‚°ã‚¤ãƒ³ä¸­: {current_user}")

# ã‚»ãƒƒã‚·ãƒ§ãƒ³å¤‰æ•°
if "messages" not in st.session_state:
    st.session_state.messages = []
if "conversation_id" not in st.session_state:
    st.session_state.conversation_id = ""
if "current_file_id" not in st.session_state:
    st.session_state.current_file_id = None
if "selected_material" not in st.session_state:
    st.session_state.selected_material = None
if "last_bot_message" not in st.session_state:
    st.session_state.last_bot_message = ""
if "audio_html" not in st.session_state:
    st.session_state.audio_html = None
if "prev_audio_bytes" not in st.session_state:
    st.session_state.prev_audio_bytes = None
if "temp_user_input" not in st.session_state:
    st.session_state.temp_user_input = ""
if "input_to_process" not in st.session_state:
    st.session_state.input_to_process = None
if "is_completed" not in st.session_state:
    st.session_state.is_completed = False

# 1. è¬›ç¾©è³‡æ–™ã®é¸æŠã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹
if not st.session_state.selected_material:
    st.subheader("ğŸ“š å­¦ç¿’ã™ã‚‹è¬›ç¾©è³‡æ–™ã‚’é¸æŠã—ã¦ãã ã•ã„")
    selected = st.radio(
        "è¬›ç¾©ãƒªã‚¹ãƒˆ",
        options=list(MATERIALS.keys()),
        index=None
    )
    
    if st.button("å­¦ç¿’ã‚’é–‹å§‹ã™ã‚‹"):
        if selected:
            st.session_state.selected_material = selected
            st.rerun()
        else:
            st.warning("è¬›ç¾©è³‡æ–™ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚")
    st.stop() # é¸æŠã•ã‚Œã‚‹ã¾ã§ä¸‹ã®å‡¦ç†ï¼ˆãƒãƒ£ãƒƒãƒˆï¼‰ã«é€²ã¾ãªã„

# é¸æŠã•ã‚ŒãŸæƒ…å ±ã‚’ä¿æŒ
target_material_path = MATERIALS[st.session_state.selected_material]

# --- ç·Šæ€¥ãƒªã‚»ãƒƒãƒˆ ---
if st.sidebar.button("âš ï¸ ä¼šè©±ã‚’ãƒªã‚»ãƒƒãƒˆ"):
    for key in list(st.session_state.keys()):
        if key not in ["username"]: # ãƒ­ã‚°ã‚¤ãƒ³æƒ…å ±ã¯æ®‹ã™
            del st.session_state[key]
    st.rerun()

# 3. è‡ªå‹•åˆæœŸåŒ–ï¼ˆä¿®æ­£ç‰ˆï¼šAPIã‚’å©ã‹ãšã€é™çš„ã«é–‹å§‹ã™ã‚‹ï¼‰
if not st.session_state.conversation_id:
    # ã¾ã ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å±¥æ­´ãŒãªã„å ´åˆã®ã¿å®Ÿè¡Œ
    if not st.session_state.messages:
        with st.spinner("ã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ã‚¢ãƒ¼ã‚’æº–å‚™ä¸­..."):
            
            # 1. ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã ã‘ã¯æ¸ˆã¾ã›ã¦ãŠãï¼ˆIDç¢ºä¿ï¼‰
            if not st.session_state.current_file_id:
                file_id = upload_local_file_to_dify(target_material_path, current_user)
                if file_id:
                    st.session_state.current_file_id = file_id
                else:
                    st.error("ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
                    st.stop()
            
            # 2. Difyã«ã¯ä½•ã‚‚é€ã‚‰ãšã€ã“ã“ã§å‹æ‰‹ã«ç¬¬ä¸€å£°ã‚’è¡¨ç¤ºã™ã‚‹
            static_first_msg = "æˆæ¥­å†…å®¹ã«ã¤ã„ã¦å­¦ã‚“ã ã“ã¨ã‚’æ•™ãˆã¦ãã ã•ã„ã€‚"
            
            # ç”»é¢è¡¨ç¤ºç”¨ãƒªã‚¹ãƒˆã«è¿½åŠ 
            st.session_state.messages.append({"role": "assistant", "content": static_first_msg})
            
            # ãƒ­ã‚°ä¿å­˜ç”¨ï¼ˆæ¬¡ã®ã‚¿ãƒ¼ãƒ³ã®ãŸã‚ï¼‰
            st.session_state.last_bot_message = static_first_msg
            
            # éŸ³å£°ç”Ÿæˆï¼ˆã“ã“ã ã‘ã¯OpenAI APIã‚’å©ãã¾ã™ãŒã€Difyã¯å©ãã¾ã›ã‚“ï¼‰
            st.session_state.audio_html = text_to_speech_autoplay(static_first_msg)
            
            # ç”»é¢æ›´æ–°ã—ã¦è¡¨ç¤º
            st.rerun()

# 4. ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®è¡¨ç¤º
chat_container = st.container(height=500)

with chat_container:
    for msg in st.session_state.messages:
        with st.chat_message(msg["role"]):
            st.write(msg["content"])
    if st.session_state.audio_html:
        st.markdown(st.session_state.audio_html, unsafe_allow_html=True)

if st.session_state.is_completed:
    st.success("ğŸ‰ å…¨ã¦ã®å­¦ç¿’é …ç›®ã‚’ç¢ºèªã—ã¾ã—ãŸã€‚ãŠç–²ã‚Œæ§˜ã§ã—ãŸï¼")
    st.balloons() # ãŠç¥ã„ã®æ¼”å‡º

# 5. å…¥åŠ›ã‚¨ãƒªã‚¢ & 6. å…¥åŠ›å‡¦ç†ãƒ­ã‚¸ãƒƒã‚¯ï¼ˆçµ±åˆãƒ»é †åºä¿®æ­£ç‰ˆï¼‰
st.divider()

def submit_text():
    st.session_state.input_to_process = st.session_state.temp_user_input
    st.session_state.temp_user_input = "" 

# ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆå®šç¾©ï¼ˆè¦‹ãŸç›®ã¯ å·¦:å…¥åŠ›ã€å³:ãƒã‚¤ã‚¯ï¼‰
col_input, col_mic = st.columns([6, 1])

# material_info = MATERIALS[st.session_state.selected_material]
# target_material_path = material_info["pdf"]
target_material_path = MATERIALS[st.session_state.selected_material]["pdf"]
# target_keyword_path = material_info["keywords"]
target_keyword_path = MATERIALS[st.session_state.selected_material]["keywords"]

# --- A. ãƒã‚¤ã‚¯å…¥åŠ›ã¨éŸ³å£°å‡¦ç†ï¼ˆå…ˆå‡ºã—ï¼‰ ---
with col_mic:
    audio = mic_recorder(
        start_prompt="ğŸ¤", 
        stop_prompt="â¹ï¸", 
        key='recorder', 
        format="wav"
    )

# éŸ³å£°ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹å ´åˆã€ã™ãã«å‡¦ç†ã—ã¦ session_state ã‚’æ›´æ–°ã™ã‚‹
if audio:
    if audio['bytes'] != st.session_state.prev_audio_bytes:
        st.session_state.prev_audio_bytes = audio['bytes']
        
        with st.spinner("éŸ³å£°èªè­˜ä¸­..."):
            transcribed_text = transcribe_audio(audio['bytes'])
            if transcribed_text:
                corrected_text = correct_transcript(transcribed_text)
                
                # ã€ã“ã“ãŒä¿®æ­£ã®ã‚­ãƒ¢ã€‘
                # ã¾ã ãƒ†ã‚­ã‚¹ãƒˆå…¥åŠ›æ¬„ã¯æç”»ã•ã‚Œã¦ã„ãªã„ã®ã§ã€ã“ã“ã§å€¤ã‚’ã‚»ãƒƒãƒˆã—ã¦ã‚‚ã‚¨ãƒ©ãƒ¼ã«ãªã‚Šã¾ã›ã‚“ï¼
                st.session_state.temp_user_input = corrected_text
                
                # å‰ã®ãƒœãƒƒãƒˆã®éŸ³å£°ã‚’åœæ­¢
                st.session_state.audio_html = None
                
                # ã“ã“ã§ rerun ã™ã‚‹å¿…è¦ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚
                # ã“ã®ã¾ã¾ä¸‹ã®ã‚³ãƒ¼ãƒ‰ã«é€²ã‚ã°ã€è‡ªç„¶ã«æ–°ã—ã„å€¤ãŒå…¥ã£ãŸçŠ¶æ…‹ã§å…¥åŠ›æ¬„ãŒè¡¨ç¤ºã•ã‚Œã¾ã™ã€‚

# --- B. ãƒ†ã‚­ã‚¹ãƒˆå…¥åŠ›ã‚¨ãƒªã‚¢ï¼ˆå¾Œå‡ºã—ï¼‰ ---
with col_input:
    # ã“ã“ã§åˆã‚ã¦å…¥åŠ›æ¬„ãŒæç”»ã•ã‚Œã¾ã™ã€‚
    # ä¸Šã®å‡¦ç†ã§ temp_user_input ã«å€¤ãŒå…¥ã£ã¦ã„ã‚Œã°ã€ãã‚ŒãŒåˆæœŸå€¤ã¨ã—ã¦è¡¨ç¤ºã•ã‚Œã¾ã™ã€‚
    st.text_input(
        label="ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å…¥åŠ›",
        key="temp_user_input",
        placeholder="ãƒ†ã‚­ã‚¹ãƒˆã‚’å…¥åŠ›ã—ã¦Enter...",
        label_visibility="collapsed",
        on_change=submit_text
    )

# --- C. é€ä¿¡å‡¦ç†ï¼ˆEnterãŒæŠ¼ã•ã‚ŒãŸå¾Œã®å‡¦ç†ï¼‰ ---
# ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯(submit_text)ã«ã‚ˆã£ã¦ input_to_process ã«å€¤ãŒå…¥ã£ã¦ã„ãŸã‚‰å®Ÿè¡Œ
final_prompt = None

if st.session_state.input_to_process:
    final_prompt = st.session_state.input_to_process
    st.session_state.input_to_process = None
    st.session_state.audio_html = None

# é€ä¿¡å®Ÿè¡Œ
if final_prompt:
    st.session_state.messages.append({"role": "user", "content": final_prompt})
    
    with chat_container:
        with st.chat_message("user"):
            st.write(final_prompt)

    with st.spinner("æ€è€ƒä¸­..."):
        response = send_chat_message(
            query=final_prompt,
            conversation_id=st.session_state.conversation_id,
            file_id_to_send=st.session_state.current_file_id,
            user_id=current_user
        )
        
        if response:
            st.session_state.conversation_id = response.get('conversation_id')
            answer_text = response.get('answer', '')
            is_finished = response.get('metadata', {}).get('workflow_outputs', {}).get('is_finished', False)
            if is_finished:
                st.session_state.is_completed = True
            st.session_state.messages.append({"role": "assistant", "content": answer_text})
            
            save_log_to_sheet(
                session=st.session_state.conversation_id,
                user=current_user,
                material=st.session_state.selected_material,
                system_question=st.session_state.last_bot_message,
                user_answer=final_prompt
            )
            
            st.session_state.last_bot_message = answer_text
            st.session_state.audio_html = text_to_speech_autoplay(answer_text)

            st.rerun()
