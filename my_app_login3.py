import streamlit as st
import requests
import os
import datetime
import pandas as pd
from streamlit_gsheets import GSheetsConnection
import json
import base64

# --- è¿½åŠ ãƒ©ã‚¤ãƒ–ãƒ©ãƒª ---
from streamlit_mic_recorder import mic_recorder
from openai import OpenAI

# --- ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆæ¥ç¶š ---
conn = st.connection("gsheets", type=GSheetsConnection)

# --- è¨­å®š ---
DIFY_API_KEY = st.secrets["DIFY_API_KEY"]
# .streamlit/secrets.toml ã« OPENAI_API_KEY = "sk-..." ã‚’è¨˜è¿°ã—ã¦ãã ã•ã„
openai_client = OpenAI(api_key=st.secrets["OPENAI_API_KEY"])

BASE_URL = "https://api.dify.ai/v1"
FILE_VARIABLE_KEY = "material"

# ã‚µãƒ¼ãƒãƒ¼å´ã«ã‚ã‚‹å›ºå®šãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
FIXED_FILE_PATH = "NLP11.pdf"

headers = {
    "Authorization": f"Bearer {DIFY_API_KEY}"
}

# --- ãƒ­ã‚°ã‚¤ãƒ³æ©Ÿèƒ½ ---
def login():
    """ç°¡æ˜“ãƒ­ã‚°ã‚¤ãƒ³æ©Ÿèƒ½"""
    if "username" not in st.session_state:
        st.session_state.username = None

    if not st.session_state.username:
        with st.form("login_form"):
            st.write("å­¦ç¿’ã‚’é–‹å§‹ã™ã‚‹ã«ã¯IDï¼ˆæ°åã¾ãŸã¯å­¦ç±ç•ªå·ï¼‰ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
            username_input = st.text_input("ãƒ¦ãƒ¼ã‚¶ãƒ¼ID")
            submitted = st.form_submit_button("é–‹å§‹")
            if submitted and username_input:
                st.session_state.username = username_input
                st.rerun()
        st.stop()

# --- Difyé€£æºé–¢æ•°ç¾¤ ---
def upload_local_file_to_dify(file_path, user_id):
    if not os.path.exists(file_path):
        st.error(f"ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {file_path}")
        return None

    url = f"{BASE_URL}/files/upload"
    with open(file_path, "rb") as f:
        files = {
            'file': (os.path.basename(file_path), f, 'application/pdf')
        }
        data = {'user': user_id}
        try:
            response = requests.post(url, headers=headers, files=files, data=data)
            response.raise_for_status()
            return response.json().get('id')
        except Exception as e:
            st.error(f"å†…éƒ¨ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {e}")
            return None

def send_chat_message(query, conversation_id, file_id_to_send, user_id):
    url = f"{BASE_URL}/chat-messages"
    inputs = {}
    
    if file_id_to_send:
        inputs[FILE_VARIABLE_KEY] = {
            "type": "document", 
            "transfer_method": "local_file",
            "upload_file_id": file_id_to_send
        }

    payload = {
        "inputs": inputs,
        "query": query,
        "response_mode": "blocking",
        "conversation_id": conversation_id,
        "user": user_id,
    }
    
    try:
        response = requests.post(url, headers=headers, json=payload)
        response.raise_for_status()
        return response.json()
    except Exception as e:
        st.error(f"é€šä¿¡ã‚¨ãƒ©ãƒ¼: {e}")
        return None

# --- ãƒ­ã‚°ä¿å­˜æ©Ÿèƒ½ ---
def save_log_to_sheet(username, user_input, bot_question, conversation_id):
    try:
        now = datetime.datetime.now(datetime.timezone(datetime.timedelta(hours=9))).strftime('%Y-%m-%d %H:%M:%S')
        existing_data = conn.read(spreadsheet=st.secrets["spreadsheet_url"], ttl=0)
        
        new_row = pd.DataFrame([{
            "date": now,
            "user_id": username,
            "user_input": user_input,
            "ai_response": bot_question,
            "conversation_id": conversation_id
        }])
        
        if existing_data.empty:
            updated_df = new_row
        else:
            updated_df = pd.concat([existing_data, new_row], ignore_index=True)
            
        conn.update(spreadsheet=st.secrets["spreadsheet_url"], data=updated_df)
    except Exception as e:
        st.error(f"ãƒ­ã‚°ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")

# --- éŸ³å£°å‡¦ç†é–¢æ•°ï¼ˆä¿®æ­£ç‰ˆï¼‰ ---

def transcribe_audio(audio_bytes):
    """OpenAI Whisperã‚’ä½¿ã£ã¦éŸ³å£°ã‚’ãƒ†ã‚­ã‚¹ãƒˆã«å¤‰æ›"""
    try:
        import io
        audio_file = io.BytesIO(audio_bytes)
        audio_file.name = "input.wav"
        
        transcript = openai_client.audio.transcriptions.create(
            model="whisper-1", 
            file=audio_file,
            language="ja"
        )
        return transcript.text
    except Exception as e:
        st.error(f"éŸ³å£°èªè­˜ã‚¨ãƒ©ãƒ¼: {e}")
        return ""

def text_to_speech_autoplay(text):
    """
    OpenAI TTSã‚’ä½¿ã£ã¦éŸ³å£°ã‚’ç”Ÿæˆã—ã€éè¡¨ç¤ºãƒ—ãƒ¬ãƒ¼ãƒ¤ãƒ¼ã§è‡ªå‹•å†ç”Ÿã™ã‚‹
    ä¿®æ­£ç‚¹:
    1. model="tts-1-hd" (é«˜éŸ³è³ªç‰ˆ)
    2. voice="nova" (æ—¥æœ¬èªã®ã‚¤ãƒ³ãƒˆãƒãƒ¼ã‚·ãƒ§ãƒ³ãŒæ¯”è¼ƒçš„è‡ªç„¶)
    3. style="display:none" (ãƒ—ãƒ¬ãƒ¼ãƒ¤ãƒ¼éè¡¨ç¤º)
    """
    try:
        response = openai_client.audio.speech.create(
            model="tts-1-hd", # é«˜éŸ³è³ªãƒ¢ãƒ‡ãƒ«
            voice="onyx",     # æ—¥æœ¬èªã«é©ã—ãŸå£° (alloyã¯è¨›ã‚Šã‚„ã™ã„)
            input=text
        )
        
        audio_bytes = response.content
        audio_base64 = base64.b64encode(audio_bytes).decode('utf-8')
        
        # controlså±æ€§ã‚’å‰Šé™¤ã—ã€style="display:none" ã‚’è¿½åŠ 
        audio_tag = f'<audio autoplay="true" style="display:none"><source src="data:audio/mp3;base64,{audio_base64}" type="audio/mp3"></audio>'
        
        return audio_tag
    except Exception as e:
        st.error(f"éŸ³å£°åˆæˆã‚¨ãƒ©ãƒ¼: {e}")
        return None

# ==========================================
# ãƒ¡ã‚¤ãƒ³å‡¦ç†
# ==========================================
st.set_page_config(page_title="è¬›ç¾©ã®å¾©ç¿’", page_icon="ğŸ¤–")
st.title("ğŸ¤– è¬›ç¾©æŒ¯ã‚Šè¿”ã‚Šã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ã‚¢ãƒ¼")

# 1. ãƒ­ã‚°ã‚¤ãƒ³
login()
current_user = st.session_state.username
st.sidebar.write(f"ãƒ­ã‚°ã‚¤ãƒ³ä¸­: {current_user}")

# 2. ã‚»ãƒƒã‚·ãƒ§ãƒ³å¤‰æ•°
if "messages" not in st.session_state:
    st.session_state.messages = []
if "conversation_id" not in st.session_state:
    st.session_state.conversation_id = ""
if "current_file_id" not in st.session_state:
    st.session_state.current_file_id = None
if "last_bot_message" not in st.session_state:
    st.session_state.last_bot_message = ""
if "audio_html" not in st.session_state:
    st.session_state.audio_html = None

# --- ç·Šæ€¥ãƒªã‚»ãƒƒãƒˆ ---
if st.sidebar.button("âš ï¸ ä¼šè©±ã‚’ãƒªã‚»ãƒƒãƒˆ"):
    st.session_state.conversation_id = ""
    st.session_state.messages = []
    st.session_state.current_file_id = None
    st.session_state.last_bot_message = ""
    st.session_state.audio_html = None
    st.rerun()

# 3. è‡ªå‹•åˆæœŸåŒ–
if not st.session_state.conversation_id:
    with st.spinner("ã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ã‚¢ãƒ¼ã‚’æº–å‚™ä¸­..."):
        if not st.session_state.current_file_id:
            file_id = upload_local_file_to_dify(FIXED_FILE_PATH, current_user)
            if file_id:
                st.session_state.current_file_id = file_id
            else:
                st.error("ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
                st.stop()
        
        initial_res = send_chat_message(
            query="æˆæ¥­å†…å®¹ã«ã¤ã„ã¦å­¦ã‚“ã ã“ã¨ã‚’æ•™ãˆã¦ãã ã•ã„ã€‚", 
            conversation_id="",
            file_id_to_send=st.session_state.current_file_id,
            user_id=current_user
        )
        
        if initial_res:
            st.session_state.conversation_id = initial_res.get('conversation_id')
            welcome_msg = initial_res.get('answer', '')
            st.session_state.messages.append({"role": "assistant", "content": welcome_msg})
            st.session_state.last_bot_message = welcome_msg
            
            # åˆå›éŸ³å£°å†ç”Ÿ
            audio_tag = text_to_speech_autoplay(welcome_msg)
            st.session_state.audio_html = audio_tag
            
            st.rerun()

# 4. ãƒãƒ£ãƒƒãƒˆå±¥æ­´
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.write(msg["content"])

# éŸ³å£°è‡ªå‹•å†ç”Ÿ (å§¿ã¯è¦‹ã›ãšéŸ³ã ã‘å‡ºã™)
if st.session_state.audio_html:
    st.markdown(st.session_state.audio_html, unsafe_allow_html=True)

# 5. å…¥åŠ›ã‚¨ãƒªã‚¢
st.divider()
col1, col2 = st.columns([1, 4])

with col1:
    st.write("éŸ³å£°å…¥åŠ›:")
    audio = mic_recorder(
        start_prompt="â—",
        stop_prompt="â– ",
        key='recorder',
        format="wav"
    )

user_input_text = st.chat_input("ãƒ†ã‚­ã‚¹ãƒˆã§å…¥åŠ›...")

# 6. å…¥åŠ›å‡¦ç†
final_prompt = None

if audio:
    with st.spinner("éŸ³å£°èªè­˜ä¸­..."):
        transcribed_text = transcribe_audio(audio['bytes'])
        if transcribed_text:
            final_prompt = transcribed_text
            st.session_state.audio_html = None

elif user_input_text:
    final_prompt = user_input_text
    st.session_state.audio_html = None

if final_prompt:
    st.session_state.messages.append({"role": "user", "content": final_prompt})
    with st.chat_message("user"):
        st.write(final_prompt)

    with st.spinner("æ€è€ƒä¸­..."):
        response = send_chat_message(
            query=final_prompt,
            conversation_id=st.session_state.conversation_id,
            file_id_to_send=st.session_state.current_file_id,
            user_id=current_user
        )
        
        if response:
            answer_text = response.get('answer', '')
            st.session_state.messages.append({"role": "assistant", "content": answer_text})
            
            save_log_to_sheet(
                username=current_user,
                user_input=final_prompt,
                bot_question=st.session_state.last_bot_message, 
                conversation_id=st.session_state.conversation_id
            )
            
            st.session_state.last_bot_message = answer_text
            
            # å›ç­”ã®éŸ³å£°åŒ–
            audio_tag = text_to_speech_autoplay(answer_text)
            st.session_state.audio_html = audio_tag

            st.rerun()
