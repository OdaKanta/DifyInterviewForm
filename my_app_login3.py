import streamlit as st
import requests
import os
import datetime
import pandas as pd
from streamlit_gsheets import GSheetsConnection
import json
import base64
import io

# --- è¿½åŠ ãƒ©ã‚¤ãƒ–ãƒ©ãƒª ---
from streamlit_mic_recorder import mic_recorder
from openai import OpenAI

# --- ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆæ¥ç¶š ---
conn = st.connection("gsheets", type=GSheetsConnection)

# --- è¨­å®š ---
DIFY_API_KEY = st.secrets["DIFY_API_KEY"]
openai_client = OpenAI(api_key=st.secrets["OPENAI_API_KEY"])

BASE_URL = "https://api.dify.ai/v1"
FILE_VARIABLE_KEY = "material"
FIXED_FILE_PATH = "NLP11.pdf"

headers = {
    "Authorization": f"Bearer {DIFY_API_KEY}"
}

# --- ãƒ­ã‚°ã‚¤ãƒ³æ©Ÿèƒ½ ---
def login():
    if "username" not in st.session_state:
        st.session_state.username = None
    if not st.session_state.username:
        with st.form("login_form"):
            st.write("å­¦ç¿’ã‚’é–‹å§‹ã™ã‚‹ã«ã¯IDï¼ˆæ°åã¾ãŸã¯å­¦ç±ç•ªå·ï¼‰ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
            username_input = st.text_input("ãƒ¦ãƒ¼ã‚¶ãƒ¼ID")
            submitted = st.form_submit_button("é–‹å§‹")
            if submitted and username_input:
                st.session_state.username = username_input
                st.rerun()
        st.stop()

# --- Difyé€£æºé–¢æ•°ç¾¤ ---
def upload_local_file_to_dify(file_path, user_id):
    if not os.path.exists(file_path):
        st.error(f"ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {file_path}")
        return None
    url = f"{BASE_URL}/files/upload"
    with open(file_path, "rb") as f:
        files = {'file': (os.path.basename(file_path), f, 'application/pdf')}
        data = {'user': user_id}
        try:
            response = requests.post(url, headers=headers, files=files, data=data)
            response.raise_for_status()
            return response.json().get('id')
        except Exception as e:
            st.error(f"å†…éƒ¨ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {e}")
            return None

def send_chat_message(query, conversation_id, file_id_to_send, user_id):
    url = f"{BASE_URL}/chat-messages"
    inputs = {}
    if file_id_to_send:
        inputs[FILE_VARIABLE_KEY] = {
            "type": "document", 
            "transfer_method": "local_file",
            "upload_file_id": file_id_to_send
        }
    payload = {
        "inputs": inputs,
        "query": query,
        "response_mode": "blocking",
        "conversation_id": conversation_id,
        "user": user_id,
    }
    try:
        response = requests.post(url, headers=headers, json=payload)
        response.raise_for_status()
        return response.json()
    except Exception as e:
        st.error(f"é€šä¿¡ã‚¨ãƒ©ãƒ¼: {e}")
        return None

# --- ãƒ­ã‚°ä¿å­˜æ©Ÿèƒ½ ---
def save_log_to_sheet(username, user_input, bot_question, conversation_id):
    try:
        now = datetime.datetime.now(datetime.timezone(datetime.timedelta(hours=9))).strftime('%Y-%m-%d %H:%M:%S')
        existing_data = conn.read(spreadsheet=st.secrets["spreadsheet_url"], ttl=0)
        new_row = pd.DataFrame([{
            "date": now,
            "user_id": username,
            "user_input": user_input,
            "ai_response": bot_question,
            "conversation_id": conversation_id
        }])
        if existing_data.empty:
            updated_df = new_row
        else:
            updated_df = pd.concat([existing_data, new_row], ignore_index=True)
        conn.update(spreadsheet=st.secrets["spreadsheet_url"], data=updated_df)
    except Exception as e:
        st.error(f"ãƒ­ã‚°ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")

# --- éŸ³å£°å‡¦ç†é–¢æ•° ---
def transcribe_audio(audio_bytes):
    try:
        audio_file = io.BytesIO(audio_bytes)
        audio_file.name = "input.wav"
        transcript = openai_client.audio.transcriptions.create(
            model="whisper-1", file=audio_file, language="ja"
        )
        return transcript.text
    except Exception as e:
        st.error(f"éŸ³å£°èªè­˜ã‚¨ãƒ©ãƒ¼: {e}")
        return ""

def text_to_speech_autoplay(text):
    try:
        response = openai_client.audio.speech.create(
            model="tts-1-hd", voice="nova", input=text
        )
        audio_bytes = response.content
        audio_base64 = base64.b64encode(audio_bytes).decode('utf-8')
        audio_tag = f'<audio autoplay="true" style="display:none"><source src="data:audio/mp3;base64,{audio_base64}" type="audio/mp3"></audio>'
        return audio_tag
    except Exception as e:
        st.error(f"éŸ³å£°åˆæˆã‚¨ãƒ©ãƒ¼: {e}")
        return None

# ==========================================
# ãƒ¡ã‚¤ãƒ³å‡¦ç†
# ==========================================
st.set_page_config(page_title="è¬›ç¾©ã®å¾©ç¿’", page_icon="ğŸ¤–")
st.title("ğŸ¤– è¬›ç¾©æŒ¯ã‚Šè¿”ã‚Šã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ã‚¢ãƒ¼ä½ç½®èª¿æ•´2")

login()
current_user = st.session_state.username
st.sidebar.write(f"ãƒ­ã‚°ã‚¤ãƒ³ä¸­: {current_user}")

# ã‚»ãƒƒã‚·ãƒ§ãƒ³å¤‰æ•°
if "messages" not in st.session_state:
    st.session_state.messages = []
if "conversation_id" not in st.session_state:
    st.session_state.conversation_id = ""
if "current_file_id" not in st.session_state:
    st.session_state.current_file_id = None
if "last_bot_message" not in st.session_state:
    st.session_state.last_bot_message = ""
if "audio_html" not in st.session_state:
    st.session_state.audio_html = None
if "prev_audio_bytes" not in st.session_state:
    st.session_state.prev_audio_bytes = None

# ã€è¿½åŠ ã€‘ãƒ†ã‚­ã‚¹ãƒˆå…¥åŠ›å‡¦ç†ç”¨ã®ä¸€æ™‚å¤‰æ•°
if "temp_user_input" not in st.session_state:
    st.session_state.temp_user_input = ""
if "input_to_process" not in st.session_state:
    st.session_state.input_to_process = None

# --- ç·Šæ€¥ãƒªã‚»ãƒƒãƒˆ ---
if st.sidebar.button("âš ï¸ ä¼šè©±ã‚’ãƒªã‚»ãƒƒãƒˆ"):
    for key in list(st.session_state.keys()):
        if key not in ["username"]: # ãƒ­ã‚°ã‚¤ãƒ³æƒ…å ±ã¯æ®‹ã™
            del st.session_state[key]
    st.rerun()

# 3. è‡ªå‹•åˆæœŸåŒ–
if not st.session_state.conversation_id:
    with st.spinner("ã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ã‚¢ãƒ¼ã‚’æº–å‚™ä¸­..."):
        if not st.session_state.current_file_id:
            file_id = upload_local_file_to_dify(FIXED_FILE_PATH, current_user)
            if file_id:
                st.session_state.current_file_id = file_id
            else:
                st.error("ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
                st.stop()
        
        # ã€ä¿®æ­£ã€‘ã“ã“ã‚’ã€Œãƒœãƒƒãƒˆã¸ã®æŒ‡ç¤ºã€ã«å¤‰ãˆã¾ã™
        # ä»¥å‰: "æˆæ¥­å†…å®¹ã«ã¤ã„ã¦å­¦ã‚“ã ã“ã¨ã‚’æ•™ãˆã¦ãã ã•ã„ã€‚" (ã“ã‚Œã‚’ãƒ¦ãƒ¼ã‚¶ãŒè¨€ã£ãŸã“ã¨ã«ãªã£ã¦ã„ãŸ)
        # ä»Šå›: ãƒœãƒƒãƒˆã«ã€Œãã®ã‚»ãƒªãƒ•ã‚’è¨€ã£ã¦ãã‚Œã€ã¨å‘½ä»¤ã—ã¾ã™ã€‚
        initial_instruction = "é¢æ¥ã‚’é–‹å§‹ã—ã¾ã™ã€‚ç§ï¼ˆå­¦ç¿’è€…ï¼‰ã«å¯¾ã—ã¦ã€ã¾ãšã¯ã€æˆæ¥­å†…å®¹ã«ã¤ã„ã¦å­¦ã‚“ã ã“ã¨ã‚’æ•™ãˆã¦ãã ã•ã„ã€‚ã€ã¨ã„ã†è³ªå•ã‹ã‚‰å§‹ã‚ã¦ãã ã•ã„ã€‚æŒ¨æ‹¶ã‚„å‰ç½®ãã¯ä¸è¦ã§ã™ã€‚"

        initial_res = send_chat_message(
            query=initial_instruction, 
            conversation_id="",
            file_id_to_send=st.session_state.current_file_id,
            user_id=current_user
        )
        
        if initial_res:
            st.session_state.conversation_id = initial_res.get('conversation_id')
            welcome_msg = initial_res.get('answer', '')
            
            # ã“ã‚Œã§ welcome_msg ã«ã€Œæˆæ¥­å†…å®¹ã«ã¤ã„ã¦ï½ã€ãŒå…¥ã£ã¦ãã‚‹ã¯ãšã§ã™
            st.session_state.messages.append({"role": "assistant", "content": welcome_msg})
            st.session_state.last_bot_message = welcome_msg
            st.session_state.audio_html = text_to_speech_autoplay(welcome_msg)
            st.rerun()

# 4. ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®è¡¨ç¤º
chat_container = st.container(height=500)

with chat_container:
    for msg in st.session_state.messages:
        with st.chat_message(msg["role"]):
            st.write(msg["content"])
    if st.session_state.audio_html:
        st.markdown(st.session_state.audio_html, unsafe_allow_html=True)

# 5. å…¥åŠ›ã‚¨ãƒªã‚¢ï¼ˆä½ç½®ã‚ºãƒ¬ä¿®æ­£ç‰ˆï¼‰
st.divider()

def submit_text():
    st.session_state.input_to_process = st.session_state.temp_user_input
    st.session_state.temp_user_input = "" 

# 1. vertical_alignment ã‚’å‰Šé™¤ã—ã¾ã™ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®ä¸Šæƒãˆã«ã™ã‚‹ï¼‰
col_input, col_mic = st.columns([6, 1])

with col_input:
    st.text_input(
        label="ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å…¥åŠ›",
        key="temp_user_input",
        placeholder="ãƒ†ã‚­ã‚¹ãƒˆã‚’å…¥åŠ›ã—ã¦Enter...",
        label_visibility="collapsed",
        on_change=submit_text
    )

with col_mic:
    audio = mic_recorder(
        start_prompt="ğŸ¤", 
        stop_prompt="â¹ï¸", 
        key='recorder', 
        format="wav"
    )

# 6. å…¥åŠ›å‡¦ç†ãƒ­ã‚¸ãƒƒã‚¯
final_prompt = None

# A. éŸ³å£°å…¥åŠ›ãƒã‚§ãƒƒã‚¯
if audio:
    if audio['bytes'] != st.session_state.prev_audio_bytes:
        st.session_state.prev_audio_bytes = audio['bytes']
        with st.spinner("éŸ³å£°èªè­˜ä¸­..."):
            transcribed_text = transcribe_audio(audio['bytes'])
            if transcribed_text:
                final_prompt = transcribed_text
                st.session_state.audio_html = None
    else:
        pass

# B. ãƒ†ã‚­ã‚¹ãƒˆå…¥åŠ›ãƒã‚§ãƒƒã‚¯ï¼ˆã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯çµŒç”±ï¼‰
elif st.session_state.input_to_process:
    final_prompt = st.session_state.input_to_process
    st.session_state.input_to_process = None # å‡¦ç†æ¸ˆã¿ãƒ•ãƒ©ã‚°ã‚’ä¸‹ã‚ã™
    st.session_state.audio_html = None

# C. é€ä¿¡å‡¦ç†
if final_prompt:
    st.session_state.messages.append({"role": "user", "content": final_prompt})
    
    with chat_container:
        with st.chat_message("user"):
            st.write(final_prompt)

    with st.spinner("æ€è€ƒä¸­..."):
        response = send_chat_message(
            query=final_prompt,
            conversation_id=st.session_state.conversation_id,
            file_id_to_send=st.session_state.current_file_id,
            user_id=current_user
        )
        
        if response:
            answer_text = response.get('answer', '')
            st.session_state.messages.append({"role": "assistant", "content": answer_text})
            
            save_log_to_sheet(
                username=current_user,
                user_input=final_prompt,
                bot_question=st.session_state.last_bot_message, 
                conversation_id=st.session_state.conversation_id
            )
            
            st.session_state.last_bot_message = answer_text
            st.session_state.audio_html = text_to_speech_autoplay(answer_text)

            st.rerun()
