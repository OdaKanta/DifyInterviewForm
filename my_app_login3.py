import streamlit as st
import requests
import os
import datetime
import pandas as pd
from streamlit_gsheets import GSheetsConnection
import json
import base64

# --- è¿½åŠ ãƒ©ã‚¤ãƒ–ãƒ©ãƒª ---
from streamlit_mic_recorder import mic_recorder
from openai import OpenAI

# --- ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆæ¥ç¶š ---
conn = st.connection("gsheets", type=GSheetsConnection)

# --- è¨­å®š ---
DIFY_API_KEY = st.secrets["DIFY_API_KEY"]
# ã€è¿½åŠ ã€‘OpenAIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®åˆæœŸåŒ– (TTS/STTç”¨)
# .streamlit/secrets.toml ã« OPENAI_API_KEY = "sk-..." ã‚’è¨˜è¿°ã—ã¦ãã ã•ã„
openai_client = OpenAI(api_key=st.secrets["OPENAI_API_KEY"])

BASE_URL = "https://api.dify.ai/v1"
FILE_VARIABLE_KEY = "material"

# ã‚µãƒ¼ãƒãƒ¼å´ã«ã‚ã‚‹å›ºå®šãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
FIXED_FILE_PATH = "NLP11.pdf"

headers = {
    "Authorization": f"Bearer {DIFY_API_KEY}"
}

# --- ãƒ­ã‚°ã‚¤ãƒ³æ©Ÿèƒ½ ---
def login():
    """ç°¡æ˜“ãƒ­ã‚°ã‚¤ãƒ³æ©Ÿèƒ½"""
    if "username" not in st.session_state:
        st.session_state.username = None

    if not st.session_state.username:
        with st.form("login_form"):
            st.write("å­¦ç¿’ã‚’é–‹å§‹ã™ã‚‹ã«ã¯IDï¼ˆæ°åã¾ãŸã¯å­¦ç±ç•ªå·ï¼‰ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
            username_input = st.text_input("ãƒ¦ãƒ¼ã‚¶ãƒ¼ID")
            submitted = st.form_submit_button("é–‹å§‹")
            if submitted and username_input:
                st.session_state.username = username_input
                st.rerun()
        st.stop()

# --- Difyé€£æºé–¢æ•°ç¾¤ ---
def upload_local_file_to_dify(file_path, user_id):
    if not os.path.exists(file_path):
        st.error(f"ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {file_path}")
        return None

    url = f"{BASE_URL}/files/upload"
    with open(file_path, "rb") as f:
        files = {
            'file': (os.path.basename(file_path), f, 'application/pdf')
        }
        data = {'user': user_id}
        try:
            response = requests.post(url, headers=headers, files=files, data=data)
            response.raise_for_status()
            return response.json().get('id')
        except Exception as e:
            st.error(f"å†…éƒ¨ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {e}")
            return None

def send_chat_message(query, conversation_id, file_id_to_send, user_id):
    url = f"{BASE_URL}/chat-messages"
    inputs = {}
    
    if file_id_to_send:
        inputs[FILE_VARIABLE_KEY] = {
            "type": "document", 
            "transfer_method": "local_file",
            "upload_file_id": file_id_to_send
        }

    payload = {
        "inputs": inputs,
        "query": query,
        "response_mode": "blocking",
        "conversation_id": conversation_id,
        "user": user_id,
    }
    
    try:
        response = requests.post(url, headers=headers, json=payload)
        response.raise_for_status()
        return response.json()
    except Exception as e:
        st.error(f"é€šä¿¡ã‚¨ãƒ©ãƒ¼: {e}")
        return None

# --- ãƒ­ã‚°ä¿å­˜æ©Ÿèƒ½ ---
def save_log_to_sheet(username, user_input, bot_question, conversation_id):
    try:
        now = datetime.datetime.now(datetime.timezone(datetime.timedelta(hours=9))).strftime('%Y-%m-%d %H:%M:%S')
        existing_data = conn.read(spreadsheet=st.secrets["spreadsheet_url"], ttl=0)
        
        new_row = pd.DataFrame([{
            "date": now,
            "user_id": username,
            "user_input": user_input,
            "ai_response": bot_question,
            "conversation_id": conversation_id
        }])
        
        if existing_data.empty:
            updated_df = new_row
        else:
            updated_df = pd.concat([existing_data, new_row], ignore_index=True)
            
        conn.update(spreadsheet=st.secrets["spreadsheet_url"], data=updated_df)
    except Exception as e:
        st.error(f"ãƒ­ã‚°ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")

# --- ã€æ–°è¦è¿½åŠ ã€‘éŸ³å£°å‡¦ç†é–¢æ•° ---

def transcribe_audio(audio_bytes):
    """OpenAI Whisperã‚’ä½¿ã£ã¦éŸ³å£°ã‚’ãƒ†ã‚­ã‚¹ãƒˆã«å¤‰æ›"""
    try:
        # OpenAI APIã¯ãƒ•ã‚¡ã‚¤ãƒ«ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’å¿…è¦ã¨ã™ã‚‹ãŸã‚ã€ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ç­‰ã¯ä½¿ã‚ãš
        # io.BytesIOã«åå‰ã‚’ã¤ã‘ã¦æ¸¡ã™ãƒ†ã‚¯ãƒ‹ãƒƒã‚¯ã‚’ä½¿ã„ã¾ã™
        import io
        audio_file = io.BytesIO(audio_bytes)
        audio_file.name = "input.wav" # æ‹¡å¼µå­ãŒé‡è¦
        
        transcript = openai_client.audio.transcriptions.create(
            model="whisper-1", 
            file=audio_file,
            language="ja" # æ—¥æœ¬èªã‚’æŒ‡å®šã™ã‚‹ã¨ç²¾åº¦å‘ä¸Š
        )
        return transcript.text
    except Exception as e:
        st.error(f"éŸ³å£°èªè­˜ã‚¨ãƒ©ãƒ¼: {e}")
        return ""

def text_to_speech_autoplay(text):
    """OpenAI TTSã‚’ä½¿ã£ã¦ãƒ†ã‚­ã‚¹ãƒˆã‚’éŸ³å£°ã«å¤‰æ›ã—ã€è‡ªå‹•å†ç”Ÿç”¨HTMLã‚’ç”Ÿæˆ"""
    try:
        response = openai_client.audio.speech.create(
            model="tts-1",
            voice="alloy", # alloy, echo, fable, onyx, nova, shimmer ã‹ã‚‰é¸æŠå¯
            input=text
        )
        
        # éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’Base64ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã—ã¦HTML Audioã‚¿ã‚°ã«åŸ‹ã‚è¾¼ã‚€
        audio_bytes = response.content
        audio_base64 = base64.b64encode(audio_bytes).decode('utf-8')
        audio_tag = f'<audio autoplay="true" controls><source src="data:audio/mp3;base64,{audio_base64}" type="audio/mp3"></audio>'
        
        return audio_tag
    except Exception as e:
        st.error(f"éŸ³å£°åˆæˆã‚¨ãƒ©ãƒ¼: {e}")
        return None

# ==========================================
# ãƒ¡ã‚¤ãƒ³å‡¦ç†
# ==========================================
st.set_page_config(page_title="è¬›ç¾©ã®å¾©ç¿’", page_icon="ğŸ¤–")
st.title("ğŸ¤– è¬›ç¾©æŒ¯ã‚Šè¿”ã‚Šã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ã‚¢ãƒ¼")

# 1. ãƒ­ã‚°ã‚¤ãƒ³ & ã‚»ãƒƒã‚·ãƒ§ãƒ³åˆæœŸåŒ–
login()
current_user = st.session_state.username
st.sidebar.write(f"ãƒ­ã‚°ã‚¤ãƒ³ä¸­: {current_user}")

if "messages" not in st.session_state:
    st.session_state.messages = []
if "conversation_id" not in st.session_state:
    st.session_state.conversation_id = ""
if "current_file_id" not in st.session_state:
    st.session_state.current_file_id = None
if "last_bot_message" not in st.session_state:
    st.session_state.last_bot_message = ""
# ã€è¿½åŠ ã€‘éŸ³å£°å†ç”Ÿç”¨ã®HTMLã‚’ä¿æŒã™ã‚‹å¤‰æ•°
if "audio_html" not in st.session_state:
    st.session_state.audio_html = None

# --- ç·Šæ€¥ãƒªã‚»ãƒƒãƒˆãƒœã‚¿ãƒ³ ---
if st.sidebar.button("âš ï¸ ä¼šè©±ã‚’ãƒªã‚»ãƒƒãƒˆ"):
    st.session_state.conversation_id = ""
    st.session_state.messages = []
    st.session_state.current_file_id = None
    st.session_state.last_bot_message = ""
    st.session_state.audio_html = None
    st.rerun()

# 2. è‡ªå‹•åˆæœŸåŒ–ï¼ˆãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ & åˆå›è³ªå•ï¼‰
if not st.session_state.conversation_id:
    with st.spinner("ã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ã‚¢ãƒ¼ã‚’æº–å‚™ä¸­..."):
        if not st.session_state.current_file_id:
            file_id = upload_local_file_to_dify(FIXED_FILE_PATH, current_user)
            if file_id:
                st.session_state.current_file_id = file_id
            else:
                st.error("ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
                st.stop()
        
        initial_res = send_chat_message(
            query="æˆæ¥­å†…å®¹ã«ã¤ã„ã¦å­¦ã‚“ã ã“ã¨ã‚’æ•™ãˆã¦ãã ã•ã„ã€‚", 
            conversation_id="",
            file_id_to_send=st.session_state.current_file_id,
            user_id=current_user
        )
        
        if initial_res:
            st.session_state.conversation_id = initial_res.get('conversation_id')
            welcome_msg = initial_res.get('answer', '')
            st.session_state.messages.append({"role": "assistant", "content": welcome_msg})
            st.session_state.last_bot_message = welcome_msg
            
            # åˆå›ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚‚éŸ³å£°å†ç”Ÿã™ã‚‹å ´åˆ
            audio_tag = text_to_speech_autoplay(welcome_msg)
            st.session_state.audio_html = audio_tag
            
            st.rerun()

# 3. ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®è¡¨ç¤º
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.write(msg["content"])

# ã€è¿½åŠ ã€‘éŸ³å£°è‡ªå‹•å†ç”Ÿï¼ˆæœ€æ–°ã®AIå¿œç­”ãŒã‚ã‚‹å ´åˆã€ç”»é¢ä¸Šéƒ¨ã‚„æœ«å°¾ã§å†ç”Ÿã•ã‚Œã‚‹ï¼‰
#  st.empty() ã‚’ä½¿ã£ã¦ã€å†ç”ŸãŒçµ‚ã‚ã£ãŸã‚‰æ¶ˆã™åˆ¶å¾¡ã‚‚å¯èƒ½ã§ã™ãŒã€å±¥æ­´ã«æ®‹ã‚‰ãªã„ã‚ˆã†ã«ã“ã“ã§è¡¨ç¤º
if st.session_state.audio_html:
    st.markdown(st.session_state.audio_html, unsafe_allow_html=True)
    # ä¸€åº¦å†ç”Ÿç”¨ã«è¡¨ç¤ºã—ãŸã‚‰ã€ãƒªãƒ­ãƒ¼ãƒ‰æ™‚ã«å†å†ç”Ÿã•ã‚Œãªã„ã‚ˆã†ã«ã‚¯ãƒªã‚¢ã—ãŸã„ãŒã€
    # Streamlitã®ãƒ©ã‚¤ãƒ•ã‚µã‚¤ã‚¯ãƒ«ä¸Šã€ã“ã“ã‚’Noneã«ã™ã‚‹ã¨å³åº§ã«æ¶ˆãˆã¦å†ç”Ÿã•ã‚Œãªã„ãŸã‚ã€
    # æ–°ã—ã„å…¥åŠ›ãŒã‚ã£ãŸã‚¿ã‚¤ãƒŸãƒ³ã‚°ã§ã‚¯ãƒªã‚¢ã•ã‚Œã‚‹é‹ç”¨ã«ã—ã¾ã™ã€‚

# 4. å…¥åŠ›ã‚¨ãƒªã‚¢ï¼ˆéŸ³å£° OR ãƒ†ã‚­ã‚¹ãƒˆï¼‰
st.divider()
col1, col2 = st.columns([1, 4])

# éŸ³å£°å…¥åŠ›ãƒœã‚¿ãƒ³
with col1:
    st.write("éŸ³å£°å…¥åŠ›:")
    audio = mic_recorder(
        start_prompt="éŒ²éŸ³é–‹å§‹",
        stop_prompt="éŒ²éŸ³çµ‚äº†",
        key='recorder',
        format="wav" # Whisperã¯wavå¯¾å¿œ
    )

# ãƒ†ã‚­ã‚¹ãƒˆå…¥åŠ›ãƒœãƒƒã‚¯ã‚¹
user_input_text = st.chat_input("ãƒ†ã‚­ã‚¹ãƒˆã§å…¥åŠ›...")

# 5. å…¥åŠ›å‡¦ç†ãƒ­ã‚¸ãƒƒã‚¯
final_prompt = None

# A. éŸ³å£°å…¥åŠ›ãŒã‚ã£ãŸå ´åˆ
if audio:
    # mic_recorderã¯éŒ²éŸ³å®Œäº†æ™‚ã«ãƒã‚¤ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’è¿”ã—ã¾ã™
    with st.spinner("éŸ³å£°èªè­˜ä¸­..."):
        transcribed_text = transcribe_audio(audio['bytes'])
        if transcribed_text:
            final_prompt = transcribed_text
            # æ—¢å­˜ã®éŸ³å£°ãƒ—ãƒ¬ãƒ¼ãƒ¤ãƒ¼ã‚’æ¶ˆå»ï¼ˆè‡ªåˆ†ã®å£°ãŒèªè­˜ã•ã‚ŒãŸã‚‰å‰ã®éŸ³å£°ã¯ä¸è¦ï¼‰
            st.session_state.audio_html = None

# B. ãƒ†ã‚­ã‚¹ãƒˆå…¥åŠ›ãŒã‚ã£ãŸå ´åˆ
elif user_input_text:
    final_prompt = user_input_text
    st.session_state.audio_html = None

# C. å…¥åŠ›ãŒç¢ºå®šã—ãŸå ´åˆã®é€ä¿¡å‡¦ç†
if final_prompt:
    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ç™ºè¨€ã‚’è¡¨ç¤º
    st.session_state.messages.append({"role": "user", "content": final_prompt})
    with st.chat_message("user"):
        st.write(final_prompt)

    with st.spinner("AIãŒæ€è€ƒä¸­..."):
        # Difyã¸é€ä¿¡
        response = send_chat_message(
            query=final_prompt,
            conversation_id=st.session_state.conversation_id,
            file_id_to_send=st.session_state.current_file_id,
            user_id=current_user
        )
        
        if response:
            answer_text = response.get('answer', '')
            
            # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å±¥æ­´ã«è¿½åŠ 
            st.session_state.messages.append({"role": "assistant", "content": answer_text})
            
            # ãƒ­ã‚°ä¿å­˜
            save_log_to_sheet(
                username=current_user,
                user_input=final_prompt,
                bot_question=st.session_state.last_bot_message, 
                conversation_id=st.session_state.conversation_id
            )
            
            # ç›´å‰ã®è³ªå•ã‚’æ›´æ–°
            st.session_state.last_bot_message = answer_text
            
            # ã€è¿½åŠ ã€‘å›ç­”ãƒ†ã‚­ã‚¹ãƒˆã‚’éŸ³å£°ã«å¤‰æ›ã—ã¦ã‚»ãƒƒãƒˆ
            audio_tag = text_to_speech_autoplay(answer_text)
            st.session_state.audio_html = audio_tag

            # ç”»é¢æ›´æ–°ã—ã¦AIã®å›ç­”ã¨éŸ³å£°ãƒ—ãƒ¬ãƒ¼ãƒ¤ãƒ¼ã‚’è¡¨ç¤º
            st.rerun()
