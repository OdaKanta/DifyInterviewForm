import streamlit as st
import requests
import os
import datetime
import pandas as pd
from streamlit_gsheets import GSheetsConnection
import json
import base64
import io

# --- è¿½åŠ ãƒ©ã‚¤ãƒ–ãƒ©ãƒª ---
from streamlit_mic_recorder import mic_recorder
from openai import OpenAI

# --- ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆæ¥ç¶š ---
conn = st.connection("gsheets", type=GSheetsConnection)

# --- è¨­å®š ---
DIFY_API_KEY = st.secrets["DIFY_API_KEY"]
openai_client = OpenAI(api_key=st.secrets["OPENAI_API_KEY"])

BASE_URL = "https://api.dify.ai/v1"
FILE_VARIABLE_KEY = "material"
FIXED_FILE_PATH = "NLP11.pdf"

headers = {
    "Authorization": f"Bearer {DIFY_API_KEY}"
}

# --- ãƒ­ã‚°ã‚¤ãƒ³æ©Ÿèƒ½ ---
def login():
    if "username" not in st.session_state:
        st.session_state.username = None
    if not st.session_state.username:
        with st.form("login_form"):
            st.write("å­¦ç¿’ã‚’é–‹å§‹ã™ã‚‹ã«ã¯IDï¼ˆæ°åã¾ãŸã¯å­¦ç±ç•ªå·ï¼‰ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
            username_input = st.text_input("ãƒ¦ãƒ¼ã‚¶ãƒ¼ID")
            submitted = st.form_submit_button("é–‹å§‹")
            if submitted and username_input:
                st.session_state.username = username_input
                st.rerun()
        st.stop()

# --- Difyé€£æºé–¢æ•°ç¾¤ ---
def upload_local_file_to_dify(file_path, user_id):
    if not os.path.exists(file_path):
        st.error(f"ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {file_path}")
        return None
    url = f"{BASE_URL}/files/upload"
    with open(file_path, "rb") as f:
        files = {'file': (os.path.basename(file_path), f, 'application/pdf')}
        data = {'user': user_id}
        try:
            response = requests.post(url, headers=headers, files=files, data=data)
            response.raise_for_status()
            return response.json().get('id')
        except Exception as e:
            st.error(f"å†…éƒ¨ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {e}")
            return None

def send_chat_message(query, conversation_id, file_id_to_send, user_id):
    url = f"{BASE_URL}/chat-messages"
    inputs = {}
    if file_id_to_send:
        inputs[FILE_VARIABLE_KEY] = {
            "type": "document", 
            "transfer_method": "local_file",
            "upload_file_id": file_id_to_send
        }
    payload = {
        "inputs": inputs,
        "query": query,
        "response_mode": "blocking",
        "conversation_id": conversation_id,
        "user": user_id,
    }
    try:
        response = requests.post(url, headers=headers, json=payload)
        response.raise_for_status()
        return response.json()
    except Exception as e:
        st.error(f"é€šä¿¡ã‚¨ãƒ©ãƒ¼: {e}")
        return None

# --- ãƒ­ã‚°ä¿å­˜æ©Ÿèƒ½ ---
def save_log_to_sheet(username, user_input, bot_question, conversation_id):
    try:
        now = datetime.datetime.now(datetime.timezone(datetime.timedelta(hours=9))).strftime('%Y-%m-%d %H:%M:%S')
        existing_data = conn.read(spreadsheet=st.secrets["spreadsheet_url"], ttl=0)
        new_row = pd.DataFrame([{
            "date": now,
            "user_id": username,
            "user_input": user_input,
            "ai_response": bot_question,
            "conversation_id": conversation_id
        }])
        if existing_data.empty:
            updated_df = new_row
        else:
            updated_df = pd.concat([existing_data, new_row], ignore_index=True)
        conn.update(spreadsheet=st.secrets["spreadsheet_url"], data=updated_df)
    except Exception as e:
        st.error(f"ãƒ­ã‚°ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")

# --- éŸ³å£°å‡¦ç†é–¢æ•° ---
def transcribe_audio(audio_bytes):
    try:
        audio_file = io.BytesIO(audio_bytes)
        audio_file.name = "input.wav"
        transcript = openai_client.audio.transcriptions.create(
            model="whisper-1", file=audio_file, language="ja"
        )
        return transcript.text
    except Exception as e:
        st.error(f"éŸ³å£°èªè­˜ã‚¨ãƒ©ãƒ¼: {e}")
        return ""

def text_to_speech_autoplay(text):
    try:
        response = openai_client.audio.speech.create(
            model="tts-1-hd", voice="nova", input=text
        )
        audio_bytes = response.content
        audio_base64 = base64.b64encode(audio_bytes).decode('utf-8')
        audio_tag = f'<audio autoplay="true" style="display:none"><source src="data:audio/mp3;base64,{audio_base64}" type="audio/mp3"></audio>'
        return audio_tag
    except Exception as e:
        st.error(f"éŸ³å£°åˆæˆã‚¨ãƒ©ãƒ¼: {e}")
        return None

# ==========================================
# ãƒ¡ã‚¤ãƒ³å‡¦ç†
# ==========================================
st.set_page_config(page_title="è¬›ç¾©ã®å¾©ç¿’", page_icon="ğŸ¤–")
st.title("ğŸ¤– è¬›ç¾©æŒ¯ã‚Šè¿”ã‚Šã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ã‚¢ãƒ¼æ”¹è‰¯")

login()
current_user = st.session_state.username
st.sidebar.write(f"ãƒ­ã‚°ã‚¤ãƒ³ä¸­: {current_user}")

# ã‚»ãƒƒã‚·ãƒ§ãƒ³å¤‰æ•°
if "messages" not in st.session_state:
    st.session_state.messages = []
if "conversation_id" not in st.session_state:
    st.session_state.conversation_id = ""
if "current_file_id" not in st.session_state:
    st.session_state.current_file_id = None
if "last_bot_message" not in st.session_state:
    st.session_state.last_bot_message = ""
if "audio_html" not in st.session_state:
    st.session_state.audio_html = None
if "prev_audio_bytes" not in st.session_state:
    st.session_state.prev_audio_bytes = None

# --- ç·Šæ€¥ãƒªã‚»ãƒƒãƒˆ ---
if st.sidebar.button("âš ï¸ ä¼šè©±ã‚’ãƒªã‚»ãƒƒãƒˆ"):
    st.session_state.conversation_id = ""
    st.session_state.messages = []
    st.session_state.current_file_id = None
    st.session_state.last_bot_message = ""
    st.session_state.audio_html = None
    st.session_state.prev_audio_bytes = None
    st.rerun()

# 3. è‡ªå‹•åˆæœŸåŒ–
if not st.session_state.conversation_id:
    with st.spinner("ã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ã‚¢ãƒ¼ã‚’æº–å‚™ä¸­..."):
        if not st.session_state.current_file_id:
            file_id = upload_local_file_to_dify(FIXED_FILE_PATH, current_user)
            if file_id:
                st.session_state.current_file_id = file_id
            else:
                st.error("ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
                st.stop()
        
        initial_res = send_chat_message(
            query="æˆæ¥­å†…å®¹ã«ã¤ã„ã¦å­¦ã‚“ã ã“ã¨ã‚’æ•™ãˆã¦ãã ã•ã„ã€‚", 
            conversation_id="",
            file_id_to_send=st.session_state.current_file_id,
            user_id=current_user
        )
        
        if initial_res:
            st.session_state.conversation_id = initial_res.get('conversation_id')
            welcome_msg = initial_res.get('answer', '')
            st.session_state.messages.append({"role": "assistant", "content": welcome_msg})
            st.session_state.last_bot_message = welcome_msg
            st.session_state.audio_html = text_to_speech_autoplay(welcome_msg)
            st.rerun()

# 4. ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®è¡¨ç¤ºï¼ˆã“ã“ãŒå¤‰ã‚ã‚Šã¾ã—ãŸï¼ï¼‰
# å›ºå®šã®é«˜ã•ã‚’æŒ‡å®šã—ãŸã‚³ãƒ³ãƒ†ãƒŠã®ä¸­ã«ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¡¨ç¤ºã—ã¾ã™ã€‚
# ã“ã‚Œã«ã‚ˆã‚Šã€ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒå¢—ãˆã¦ã‚‚ã‚³ãƒ³ãƒ†ãƒŠå†…ã§ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«ã•ã‚Œã‚‹ã ã‘ã§ã€
# ãã®ä¸‹ã®ãƒã‚¤ã‚¯ãƒœã‚¿ãƒ³ç­‰ã¯ä½ç½®ãŒå›ºå®šã•ã‚ŒãŸã¾ã¾ã«ãªã‚Šã¾ã™ã€‚
chat_container = st.container(height=500) # é«˜ã•ã¯èª¿æ•´ã—ã¦ãã ã•ã„

with chat_container:
    for msg in st.session_state.messages:
        with st.chat_message(msg["role"]):
            st.write(msg["content"])
    
    # éŸ³å£°å†ç”Ÿç”¨ã®éš ã—è¦ç´ ã‚‚ã“ã“ã«å…¥ã‚Œã¦ãŠãã¾ã™ï¼ˆé‚ªé­”ã«ãªã‚‰ãªã„ã®ã§ï¼‰
    if st.session_state.audio_html:
        st.markdown(st.session_state.audio_html, unsafe_allow_html=True)

# 5. å…¥åŠ›ã‚¨ãƒªã‚¢ï¼ˆã‚³ãƒ³ãƒ†ãƒŠã®å¤–ã«æ›¸ãã“ã¨ã§å›ºå®šè¡¨ç¤ºã•ã‚Œã‚‹ï¼‰
st.divider()
col1, col2 = st.columns([1, 4])

with col1:
    # ã“ã“ãŒå¸¸ã«å®šä½ç½®ã«ãªã‚Šã¾ã™ï¼
    st.write("éŸ³å£°å…¥åŠ›:")
    audio = mic_recorder(start_prompt="â—", stop_prompt="â– ", key='recorder', format="wav")

user_input_text = st.chat_input("ãƒ†ã‚­ã‚¹ãƒˆã§å…¥åŠ›...")

# 6. å…¥åŠ›å‡¦ç†ãƒ­ã‚¸ãƒƒã‚¯
final_prompt = None

if audio:
    if audio['bytes'] != st.session_state.prev_audio_bytes:
        st.session_state.prev_audio_bytes = audio['bytes']
        with st.spinner("éŸ³å£°èªè­˜ä¸­..."):
            transcribed_text = transcribe_audio(audio['bytes'])
            if transcribed_text:
                final_prompt = transcribed_text
                st.session_state.audio_html = None
    else:
        pass

elif user_input_text:
    final_prompt = user_input_text
    st.session_state.audio_html = None

if final_prompt:
    st.session_state.messages.append({"role": "user", "content": final_prompt})
    
    # ã“ã“ã§ã¯ã€Œã‚³ãƒ³ãƒ†ãƒŠã®ä¸­ã€ã«æ›¸ãè¾¼ã¿ãŸã„ã®ã§ã€context managerã‚’ä½¿ã„ã¾ã™
    with chat_container:
        with st.chat_message("user"):
            st.write(final_prompt)

    with st.spinner("æ€è€ƒä¸­..."):
        response = send_chat_message(
            query=final_prompt,
            conversation_id=st.session_state.conversation_id,
            file_id_to_send=st.session_state.current_file_id,
            user_id=current_user
        )
        
        if response:
            answer_text = response.get('answer', '')
            st.session_state.messages.append({"role": "assistant", "content": answer_text})
            
            save_log_to_sheet(
                username=current_user,
                user_input=final_prompt,
                bot_question=st.session_state.last_bot_message, 
                conversation_id=st.session_state.conversation_id
            )
            
            st.session_state.last_bot_message = answer_text
            st.session_state.audio_html = text_to_speech_autoplay(answer_text)

            st.rerun()
